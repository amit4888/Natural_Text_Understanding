{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481009f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bc8bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'boston_housing', 'california_housing', 'cifar10', 'cifar100', 'fashion_mnist', 'imdb', 'mnist', 'reuters']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.datasets\n",
    "print(dir(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8faa2323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boston_housing',\n",
       " 'california_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting only the dataset names\n",
    "dataset_names = [name for name in dir(datasets) if not name.startswith('__')]\n",
    "\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecbcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b91f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston_housing - Boston housing price dataset\n",
    "# california_housing - California housing price dataset\n",
    "# cifar10 - CIFAR-10 image dataset\n",
    "# cifar100 - CIFAR-100 image dataset\n",
    "# fashion_mnist - Fashion MNIST dataset (clothing images)\n",
    "# imdb - IMDB movie reviews dataset (sentiment analysis)\n",
    "# mnist - MNIST handwritten digit dataset\n",
    "# reuters - Reuters news classification dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42769159",
   "metadata": {},
   "source": [
    "# pad Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNs need inputs of equal length (number of words per input).\n",
    "# But sentences (or reviews) are of different lengths, e.g\n",
    "\n",
    "# [23, 14, 78] → 3 words\n",
    "# [10, 34, 12, 87, 64] → 5 words\n",
    "\n",
    "# 👉 Solution: pad_sequences ensures all sequences are same length by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a88c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "vocab_size = 10000  # top 10,000 words\n",
    "max_len = 200       # max review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f67846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9debf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    1   14   20   16  835  835\n",
      "  835   51    6 1703   56   51    6  387  180   32  812   57 2327    6\n",
      "  394  437    7  676    5   58   62   24  386   12    8   61 5301  912\n",
      "   37   80  106  233]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[10001])  # Review as list of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd883b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])  # Label: 0 (negative) or 1 (positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67761c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure equal length\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b81f6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,   25,  100, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2588fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMIT KUMAR\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=max_len))  # word embeddings\n",
    "model.add(SimpleRNN(64))                                    # RNN layer\n",
    "model.add(Dense(1, activation='sigmoid'))                   # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8703591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0513343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 68ms/step - accuracy: 0.5363 - loss: 0.6875 - val_accuracy: 0.7642 - val_loss: 0.5014\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.7846 - loss: 0.4679 - val_accuracy: 0.7980 - val_loss: 0.4448\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8759 - loss: 0.3120 - val_accuracy: 0.8044 - val_loss: 0.4468\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9251 - loss: 0.1969 - val_accuracy: 0.8400 - val_loss: 0.4131\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - accuracy: 0.9671 - loss: 0.1058 - val_accuracy: 0.7872 - val_loss: 0.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16fd8e51710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9e1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.7912 - loss: 0.5663\n",
      "Test Accuracy: 0.7929999828338623\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
